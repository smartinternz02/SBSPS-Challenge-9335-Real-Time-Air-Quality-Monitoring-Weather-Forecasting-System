{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Vegetation Index Data Preprocessing\n",
    "\n",
    "## Author: Yue 'Luna' Huang\n",
    "\n",
    "### Nov 12, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "* `pyhdf` can be installed from [here](http://fhs.github.io/python-hdf4/install.html).\n",
    "\n",
    "```bash\n",
    "sudo apt-get install libhdf4-dev\n",
    "sudo pip3 install python-hdf4\n",
    "```\n",
    "\n",
    "* `GDAL` can be installed via `pip3 install`, despite some dependency issues. Codes are as below.\n",
    "\n",
    "```bash\n",
    "sudo apt-get install libgdal-dev\n",
    "sudo pip3 install --global-option=build_ext --global-option=\"-I/usr/include/gdal\" GDAL==2.2.1\n",
    "```\n",
    "\n",
    "* Run `jupyter notebook` on the remote server and connect it to localhost.\n",
    "\n",
    "```bash\n",
    "# login\n",
    "ssh -L localhost:8888:localhost:8888 kramer\n",
    "# do not launch browser in terminal\n",
    "jupyter notebook --no-browser\n",
    "```\n",
    "\n",
    "Then follow the prompt: Copy/paste this URL into your browser when you connect for the first time, to login with a token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "* We obtained data from [DATA SOURCE](https://search.earthdata.nasa.gov/search/granules?p=C194001220-LPDAAC_ECS&tl=1494721209!4!!&q=MYD13C1&ok=MYD13C1). Official documentation can be found at [DOCS](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/myd13c1), and [MOD13C2 DOCS](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod13c2_v006) is also informative.\n",
    "* We extract `CMG 0.05 Deg 16 days EVI`, whose fill value is -3000, valid range is -2000 to 10000, and scaling factor is 0.0001.\n",
    "* We extract `CMG 0.05 Deg Monthly EVI std dev`, which is standard deviation computed from input EVI pixels, whose fill value is -3000, valid range is 0 to 10000, and scaling factor is 0.0001.\n",
    "* We also examine `CMG 0.05 Deg 16 days pixel reliability` (-1--4) and just drop missing values.\n",
    "    * -1: No Data\n",
    "    * 0: Good Data (Use with confidence)\n",
    "    * 1: Marginal data (Useful, but look at other QA information)\n",
    "    * 2: Snow/Ice\n",
    "    * 3: Cloudy\n",
    "    * 4: Estimated from MODIS historic time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads\n",
    "\n",
    "After obtaining an `evi_url_list.txt` file containing all the links to downloading the `.hdf` files, I ran the following bash script to automatically download all the data.\n",
    "\n",
    "```bash\n",
    "# change directory\n",
    "cd /disk/evi\n",
    "# silently run the commands in the background\n",
    "nohup wget --content-disposition --http-user=my_username --http-password=my_password --keep-session-cookies -i evi_url_list.txt &\n",
    "# a nohup.out file will be generated to document downloading progress\n",
    "tail -f nohup.out\n",
    "# remove when finishing downloading\n",
    "rm nohup.out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from osgeo import gdal, osr\n",
    "from pyhdf.SD import SD, SDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sys.version_info[0] >= 3, \"Python 3 or a more recent version is required.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Raster:\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self,\n",
    "                 latUpper=56 - 0.1/2, longLower=72 + 0.1/2,\n",
    "                 latStep=0.1, longStep=0.1,\n",
    "                 latN=400, longN=650):\n",
    "        \"\"\" Record latitude and longitude information on the uniform grid.\n",
    "        Default to our bounding box in China.\n",
    "        \n",
    "        :param\n",
    "            latUpper, longLower:\n",
    "                float, the upper left corner of the bounding box\n",
    "            latStep, longStep:\n",
    "                float, the spatial resolution in degrees, both should be positive\n",
    "            latN, longN:\n",
    "                int, total number of observations in each dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialized values\n",
    "        self.latUpper = latUpper\n",
    "        self.longLower = longLower\n",
    "        self.latStep = latStep\n",
    "        self.longStep = longStep\n",
    "        self.latN = latN\n",
    "        self.longN = longN\n",
    "        self.latLower = latUpper - latStep * (latN - 1)\n",
    "        self.longUpper = longLower + longStep * (longN - 1)\n",
    "        # compute coordinates\n",
    "        self.lat = np.linspace(self.latLower, self.latUpper, self.latN)\n",
    "        self.long = np.linspace(self.longLower, self.longUpper, self.longN)\n",
    "        # initialize empty array\n",
    "        self.values = np.empty((self.longN, self.latN))\n",
    "        self.values.fill(np.nan)\n",
    "        \n",
    "    def fill(self, array):\n",
    "        \"\"\" Fill in the raster with the array.\n",
    "        \n",
    "        :param\n",
    "            array:\n",
    "                2 dimensional ndarray, the first element of the array should be\n",
    "                the lower left corner of the map (smallest long and lat)\n",
    "                the array is long (dimension 0) by lat (dimension 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        # check dimension\n",
    "        assert array.shape == (self.longN, self.latN), \"Dimension Mismatch.\"\n",
    "        # copy array\n",
    "        self.values = array.copy()\n",
    "    \n",
    "    def find_neighbor(self, source_raster, method):\n",
    "        \"\"\" Impute the closest observation contained in the source_raster onto this grid.\n",
    "        This is recommended for fine grids.\n",
    "        \n",
    "        :param\n",
    "            source_raster:\n",
    "                a Raster object, values will be taken from the source raster,\n",
    "                output array will be written into self.values\n",
    "            method:\n",
    "                a list of strings, should contain either 'upper' or 'lower' and either 'left' or 'right'\n",
    "                nearst neighbor (from source_raster) will be to the (say) 'upper_left' of coordinates of self\n",
    "        \"\"\"\n",
    "        \n",
    "        # extract values from source array via direct indexing\n",
    "        for selfLongIndex in range(self.longN):\n",
    "            # find source index\n",
    "            if 'left' in method:\n",
    "                sourceLongIndex = int(np.floor(\n",
    "                    (self.long[selfLongIndex] - source_raster.longLower) / source_raster.longStep))\n",
    "            elif 'right' in method:\n",
    "                sourceLongIndex = int(np.ceil(\n",
    "                    (self.long[selfLongIndex] - source_raster.longLower) / source_raster.longStep))\n",
    "            else:\n",
    "                raise Exception(\"Methods Unspecified!\")\n",
    "                \n",
    "            for selfLatIndex in range(self.latN):  \n",
    "                # find source index\n",
    "                if 'lower' in method:\n",
    "                    sourceLatIndex = int(np.floor(\n",
    "                        (self.lat[selfLatIndex] - source_raster.latLower) / source_raster.latStep))\n",
    "                elif 'upper' in method:\n",
    "                    sourceLatIndex = int(np.ceil(\n",
    "                        (self.lat[selfLatIndex] - source_raster.latLower) / source_raster.latStep))\n",
    "                else:\n",
    "                    raise Exception(\"Methods Unspecified!\")\n",
    "                # impute value\n",
    "                self.values[selfLongIndex, selfLatIndex] = source_raster.values[sourceLongIndex, sourceLatIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2raster(array, geotiffFile=None, path=\".\", varName=None, date=None, date_format=\"%Y%j\",\n",
    "                 rasterOrigin=(72, 56), pixelLatWidth=0.1, pixelLonWidth=0.1):\n",
    "    \"\"\" This function converts array to a raster and saves it to a GeoTIFF file.\n",
    "    \n",
    "    :params\n",
    "        array:\n",
    "            2-dimensional float ndarray, lat-long (x should be lat), the lower left (south-western) corner\n",
    "            should be coded as the first element in the array\n",
    "        geotiffFile:\n",
    "            string, path and file name for the GeoTIFF file, this option overrides path, varName and date\n",
    "        path:\n",
    "            string, instead of passing in the geotiffFile argument, let the function automatically generate\n",
    "            file names within this path\n",
    "        varName:\n",
    "            string, instead of passing in the geotiffFile argument, let the function automatically generate\n",
    "            file names with this variable name\n",
    "            should be in the format of \"XXX_XXX\", e.g. \"MODIS_EVI\"\n",
    "        date:\n",
    "            string, instead of passing in the geotiffFile argument, let the function automatically generate\n",
    "            file names with this date, date could be like \"2005-01-01\" or \"2005001\" (day of year)\n",
    "        date_format:\n",
    "            string, specify format for date if date is provided, defaults to day of year (e.g. \"2005001\")\n",
    "            see: https://docs.python.org/3/library/datetime.html#datetime.datetime.strptime\n",
    "        rasterOrigin:\n",
    "            float tuple, the lon-lat coordinate of the origin of the raster\n",
    "            (the largest lat / smallest lon coordinates, i.e. upper left corner)\n",
    "            defaults to the origin of the bounding box in this project\n",
    "        pixelLatWidth, pixelLonWidth:\n",
    "            float, how many degrees latitude or longitude each element in the array reprensents\n",
    "            this is spatial resolution for the array\n",
    "            defaults to 0.1 degree by 0.1 degree\n",
    "    \"\"\"\n",
    "    \n",
    "    from datetime import datetime\n",
    "    import gdal, osr\n",
    "    import os\n",
    "    \n",
    "    # assign file name and path\n",
    "    if geotiffFile is None:\n",
    "        if varName is None or date is None:\n",
    "            raise Exception(\"Please supply either the geotiffFile argument \" +\n",
    "                            \"or both arguments of varName and date.\")\n",
    "        else:\n",
    "            # automatically convert dates\n",
    "            file_path = os.path.abspath(os.path.join(\n",
    "                path, datetime.strptime(date, date_format).strftime(\"%Y-%m-%d\") + \"_\" + varName + \".tif\"))\n",
    "    else:\n",
    "        file_path = os.path.abspath(os.path.join(\n",
    "                path, geotiffFile))\n",
    "        \n",
    "    # extract bounding box\n",
    "    try:\n",
    "        rows, cols = array.shape\n",
    "    except:\n",
    "        raise Exception(\"Array needs to be two dimensional.\")\n",
    "    originLon, originLat = rasterOrigin\n",
    "    \n",
    "    # write files\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(file_path, cols, rows, 1, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((originLon, pixelLonWidth, 0,\n",
    "                               originLat, 0, - pixelLatWidth))\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    \n",
    "    # georeference\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromProj4('+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0')\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "    \n",
    "    # close files\n",
    "    outRaster = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data files on kramer are under `/disk/yogasaur/`. The subdirectory `/home/maxjiang/yogasaur/codes/` is synced with the git repository. EVI data are in `/disk/yogasaur/evi/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input file path\n",
    "file_root = os.path.abspath(\"/disk/yogasaur/evi/\")\n",
    "# define dataset name\n",
    "dataset_name = \"MYD13C1\"\n",
    "# define variables to extract\n",
    "var_name_list = [\n",
    "    'CMG 0.05 Deg 16 days EVI',\n",
    "    'CMG 0.05 Deg 16 days EVI std dev']\n",
    "# define output file path\n",
    "output_root = os.path.abspath(\"/disk/yogasaur/merge/evi/\")\n",
    "# define output variable names\n",
    "output_var_name_list = [\n",
    "    'MODIS_EVI', 'MODIS_EVISD']\n",
    "# define fill value\n",
    "fill_value = -3000\n",
    "# define scaling factor\n",
    "scaling_factor = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct file list\n",
    "files = [f for f in os.listdir(file_root) if f.startswith(dataset_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine a few files\n",
    "if False:\n",
    "    file = files[3]\n",
    "    # load hdf file\n",
    "    hdf = SD(os.path.join(file_root, file), SDC.READ)\n",
    "    # pretty print\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(hdf.datasets())\n",
    "    for var_name in var_name_list + ['CMG 0.05 Deg 16 days pixel reliability']:\n",
    "        # extract variable\n",
    "        var = hdf.select(var_name).get()\n",
    "        # flip longitude and latitude, flip latitude\n",
    "        var = np.flip(var.T, axis=1)\n",
    "        # visualize\n",
    "        plt.imshow(var.T, origin='lower')\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test first few cases\n",
    "if True:\n",
    "    files = files[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fcec9ef2a44a6196f65a060aa556f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate a raw raster\n",
    "raw_raster = Raster(\n",
    "    latUpper=90 - 0.05/2, longLower=-180 + 0.05/2,\n",
    "    latStep=0.05, longStep=0.05,\n",
    "    latN=3600, longN=7200)\n",
    "\n",
    "# initiate empty output raster\n",
    "output_raster = Raster()\n",
    "\n",
    "for file in tqdm_notebook(files, desc=\"Processing\"):\n",
    "    # parse file name, extract date\n",
    "    _, date, _, _, _ = file.split(sep=\".\")\n",
    "    date = date[1:]\n",
    "    # load hdf files\n",
    "    hdf = SD(os.path.join(file_root, file), SDC.READ)\n",
    "    for i, var_name in enumerate(var_name_list):\n",
    "        # extract variable\n",
    "        var = hdf.select(var_name).get()\n",
    "        # flip longitude and latitude, flip latitude, cast to float\n",
    "        var = np.flip(var.T, axis=1).astype(float)\n",
    "        # scale and drop fill values\n",
    "        var[var == fill_value] = np.nan\n",
    "        var = var * scaling_factor\n",
    "        # fill the raw raster with the source array\n",
    "        raw_raster.fill(var)\n",
    "        # using different methods, construct four maps\n",
    "        for method, varSuffix in [(['upper', 'left'], 'UL'),\n",
    "                                  (['upper', 'right'], 'UR'),\n",
    "                                  (['lower', 'left'], 'LL'),\n",
    "                                  (['lower', 'right'], 'LR')]:\n",
    "            # impute values (closest neighbors)\n",
    "            output_raster.find_neighbor(source_raster=raw_raster, method=method)\n",
    "            # save output\n",
    "            array2raster(array=output_raster.values,\n",
    "                         path=output_root, varName=output_var_name_list[i] + \"-\" + varSuffix, date=date)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
